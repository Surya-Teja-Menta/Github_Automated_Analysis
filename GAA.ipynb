{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f78e1c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q langchain==0.0.134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4893b9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec43e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import os, re,gc\n",
    "import openai\n",
    "\n",
    "\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd941e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "# llm = OpenAI(temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "682745a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string_into_list(string, words_per_string):\n",
    "    print(\"Max Length:\",words_per_string)\n",
    "    words = string.split()  # Split the string into individual words\n",
    "    num_strings = len(words) // words_per_string  # Calculate the number of strings needed\n",
    "    string_list = []\n",
    "    \n",
    "    for i in range(num_strings):\n",
    "        start_index = i * words_per_string\n",
    "        end_index = (i + 1) * words_per_string\n",
    "        string_list.append(\" \".join(words[start_index:end_index]))\n",
    "    print('Number of Lists:',len(string_list))\n",
    "    # Add any remaining words to the last string\n",
    "    if len(words) % words_per_string != 0:\n",
    "        string_list.append(\" \".join(words[num_strings * words_per_string:]))\n",
    "    \n",
    "    return string_list\n",
    "def get_repo_metrics(code_texts,max_code_length = 2040):\n",
    "\n",
    "  code_texts = split_string_into_list(code_texts,max_code_length)\n",
    "  output_list = []\n",
    "  for i,code_text in enumerate(code_texts):\n",
    "    prompt = \"\"\"Analyse Code and measure performance and complexity\\n\n",
    "    provide the output as\n",
    "    list of all Programming Languages that are used in the code: score of associated coding level of each Programming Language out of 10,\n",
    "    Time Complexity: score out of 10\n",
    "    Space Complexity: score out of 10\n",
    "    Overall Technical Complexity: score out of 10\n",
    "    Rule: 0 means bad level and 10 means good level\n",
    "    Provide the output in only Json Format and don't provide any else\n",
    "    Code = \n",
    "      \n",
    "    \"\"\"\n",
    "\n",
    "    input_text = prompt + code_text\n",
    "\n",
    "    # Truncate code snippet to fit within the context limit\n",
    "    truncated_code = input_text[:max_code_length]\n",
    "    messages = [{'role':'user','content':input_text}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = messages,\n",
    "        temperature = 0.7\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message['content']\n",
    "    output_list.append(output)\n",
    "    # print(output)\n",
    "   \n",
    "  return output_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7076dae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length: 2040\n",
      "Number of Lists: 4\n"
     ]
    }
   ],
   "source": [
    "jsp = get_repo_metrics(cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdea400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\\n  \"Programming Languages\": {\\n    \"C\": 8,\\n    \"C++\": 8,\\n    \"Java\": 7,\\n    \"Python\": 7,\\n    \"R\": 7,\\n    \"Go\": 6\\n  },\\n  \"Time Complexity\": 9,\\n  \"Space Complexity\": 9,\\n  \"Overall Technical Complexity\": 8\\n}', '{\\n  \"Programming Languages\": {\\n    \"Go\": 8,\\n    \"C\": 7,\\n    \"C++\": 7,\\n    \"Java\": 9,\\n    \"JavaScript\": 8,\\n    \"Python\": 9,\\n    \"R\": 7\\n  },\\n  \"Time Complexity\": 9,\\n  \"Space Complexity\": 8,\\n  \"Overall Technical Complexity\": 8\\n}', '{\\n  \"Programming Languages\": {\\n    \"Python\": 8,\\n    \"Go\": 7,\\n    \"C\": 6,\\n    \"C++\": 6,\\n    \"Java\": 7,\\n    \"R\": 8\\n  },\\n  \"Time Complexity\": 8,\\n  \"Space Complexity\": 8,\\n  \"Overall Technical Complexity\": 8\\n}', '{\\n  \"Programming Languages\": {\\n    \"Python\": 10,\\n    \"R\": 8,\\n    \"Go\": 7,\\n    \"C\": 6,\\n    \"C++\": 6,\\n    \"Java\": 6\\n  },\\n  \"Time Complexity\": 9,\\n  \"Space Complexity\": 6,\\n  \"Overall Technical Complexity\": 7\\n}', '{\\n  \"Programming Languages\": {\\n    \"Java\": 8,\\n    \"Python\": 9,\\n    \"R\": 7,\\n    \"Go\": 5,\\n    \"C\": 6,\\n    \"C++\": 6\\n  },\\n  \"Time Complexity\": 8,\\n  \"Space Complexity\": 7,\\n  \"Overall Technical Complexity\": 7\\n}']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def merge_json(json_strings):\n",
    "  try:\n",
    "\n",
    "    \"\"\"Merges multiple JSON strings into a single JSON string.\n",
    "\n",
    "    Args:\n",
    "      json_strings: A list of JSON strings.\n",
    "\n",
    "    Returns:\n",
    "      A single JSON string.\n",
    "    \"\"\"\n",
    "    mjs = []\n",
    "    if type(json_strings) == list:\n",
    "      for i,j in enumerate(json_strings):      \n",
    "        data = json.loads(json_strings[i].replace('Coding Level','Level').replace('Score','Level'))\n",
    "        # data = json.loads(json_strings[i].replace('Score','Level'))\n",
    "\n",
    "        # Create the new format\n",
    "        try:\n",
    "\n",
    "          format_2 = {\n",
    "              \"Programming Languages\": {item[\"Language\"]: item[\"Level\"] for item in data[\"Programming Languages\"]},\n",
    "              \"Time Complexity\": data[\"Time Complexity\"],\n",
    "              \"Space Complexity\": data[\"Space Complexity\"],\n",
    "              \"Overall Technical Complexity\": data[\"Overall Technical Complexity\"]\n",
    "          }\n",
    "        except Exception as e:\n",
    "          print('Key Error:',data)\n",
    "\n",
    "        # Convert the new format to a JSON string with indentation for human readability\n",
    "        formatted_json = json.dumps(format_2, indent=2)\n",
    "        mjs.append(formatted_json)\n",
    "    return mjs\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "merged_json = merge_json(jsp)\n",
    "\n",
    "print(merged_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71539003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\\n    \"Programming Languages\": [\\n        {\\n            \"Language\": \"C\",\\n            \"Level\": 8\\n        },\\n        {\\n            \"Language\": \"C++\",\\n            \"Level\": 8\\n        },\\n        {\\n            \"Language\": \"Java\",\\n            \"Level\": 7\\n        },\\n        {\\n            \"Language\": \"Python\",\\n            \"Level\": 7\\n        },\\n        {\\n            \"Language\": \"R\",\\n            \"Level\": 7\\n        },\\n        {\\n            \"Language\": \"Go\",\\n            \"Level\": 6\\n        }\\n    ],\\n    \"Time Complexity\": 9,\\n    \"Space Complexity\": 9,\\n    \"Overall Technical Complexity\": 8\\n}',\n",
       " '{\\n  \"Programming Languages\": [\\n    {\"Language\": \"Go\", \"Level\": 8},\\n    {\"Language\": \"C\", \"Level\": 7},\\n    {\"Language\": \"C++\", \"Level\": 7},\\n    {\"Language\": \"Java\", \"Level\": 9},\\n    {\"Language\": \"JavaScript\", \"Level\": 8},\\n    {\"Language\": \"Python\", \"Level\": 9},\\n    {\"Language\": \"R\", \"Level\": 7}\\n  ],\\n  \"Time Complexity\": 9,\\n  \"Space Complexity\": 8,\\n  \"Overall Technical Complexity\": 8\\n}',\n",
       " '{\\n  \"Programming Languages\": [\\n    {\\n      \"Language\": \"Python\",\\n      \"Level\": 8\\n    },\\n    {\\n      \"Language\": \"Go\",\\n      \"Level\": 7\\n    },\\n    {\\n      \"Language\": \"C\",\\n      \"Level\": 6\\n    },\\n    {\\n      \"Language\": \"C++\",\\n      \"Level\": 6\\n    },\\n    {\\n      \"Language\": \"Java\",\\n      \"Level\": 7\\n    },\\n    {\\n      \"Language\": \"R\",\\n      \"Level\": 8\\n    }\\n  ],\\n  \"Time Complexity\": 8,\\n  \"Space Complexity\": 8,\\n  \"Overall Technical Complexity\": 8\\n}',\n",
       " '{\\n  \"Programming Languages\": [\\n    {\\n      \"Language\": \"Python\",\\n      \"Coding Level\": 10\\n    },\\n    {\\n      \"Language\": \"R\",\\n      \"Coding Level\": 8\\n    },\\n    {\\n      \"Language\": \"Go\",\\n      \"Coding Level\": 7\\n    },\\n    {\\n      \"Language\": \"C\",\\n      \"Coding Level\": 6\\n    },\\n    {\\n      \"Language\": \"C++\",\\n      \"Coding Level\": 6\\n    },\\n    {\\n      \"Language\": \"Java\",\\n      \"Coding Level\": 6\\n    }\\n  ],\\n  \"Time Complexity\": 9,\\n  \"Space Complexity\": 6,\\n  \"Overall Technical Complexity\": 7\\n}',\n",
       " '{\\n  \"Programming Languages\": [\\n    {\\n      \"Language\": \"Java\",\\n      \"Level\": 8\\n    },\\n    {\\n      \"Language\": \"Python\",\\n      \"Level\": 9\\n    },\\n    {\\n      \"Language\": \"R\",\\n      \"Level\": 7\\n    },\\n    {\\n      \"Language\": \"Go\",\\n      \"Level\": 5\\n    },\\n    {\\n      \"Language\": \"C\",\\n      \"Level\": 6\\n    },\\n    {\\n      \"Language\": \"C++\",\\n      \"Level\": 6\\n    }\\n  ],\\n  \"Time Complexity\": 8,\\n  \"Space Complexity\": 7,\\n  \"Overall Technical Complexity\": 7\\n}']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec8bc405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Programming Languages:\n",
      "{\n",
      "  \"C\": 6.1875,\n",
      "  \"C++\": 6.1875,\n",
      "  \"Java\": 7.375,\n",
      "  \"Python\": 9.0,\n",
      "  \"R\": 7.375,\n",
      "  \"Go\": 6.0,\n",
      "  \"JavaScript\": 8\n",
      "}\n",
      "\n",
      "Combined Complexities:\n",
      "{\n",
      "  \"Time Complexity\": 8.375,\n",
      "  \"Space Complexity\": 7.0625,\n",
      "  \"Overall Technical Complexity\": 7.25\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def combine_json(json_strings):\n",
    "  merged_json = {}\n",
    "\n",
    "  for json_string in json_strings:\n",
    "      json_data = json.loads(json_string)\n",
    "      for key, value in json_data.items():\n",
    "          if key in merged_json:\n",
    "              merged_json[key] = (merged_json[key] + value) / 2\n",
    "          else:\n",
    "              merged_json[key] = value\n",
    "\n",
    "  return json.dumps(merged_json, indent=2)\n",
    "\n",
    "# Method to combine programming languages\n",
    "def combine_programming_languages(dict_list):\n",
    "  # Extract programming languages dictionaries\n",
    "  language_dicts = [json.loads(d).get(\"Programming Languages\", {}) for d in dict_list]\n",
    "  \n",
    "  # Combine programming languages using the combine_json method\n",
    "  combined_languages = combine_json([json.dumps(lang_dict) for lang_dict in language_dicts])\n",
    "  \n",
    "  return json.loads(combined_languages)\n",
    "\n",
    "# Method to combine complexities (Time, Space, Technical)\n",
    "def combine_complexities(dict_list):\n",
    "  # Initialize dictionary for all complexities\n",
    "  all_complexities = {}\n",
    "\n",
    "  for d in dict_list:\n",
    "    d = json.loads(d)\n",
    "    # Combine complexities for each dictionary\n",
    "    for key, value in d.items():\n",
    "      if key != \"Programming Languages\":        \n",
    "        if key in all_complexities:\n",
    "            all_complexities[key] = (all_complexities[key] + value) / 2\n",
    "        else:\n",
    "            all_complexities[key] = value\n",
    "\n",
    "  return all_complexities\n",
    "\n",
    "combined_languages = combine_programming_languages(merged_json)\n",
    "print(\"Combined Programming Languages:\")\n",
    "print(json.dumps(combined_languages, indent=2))\n",
    "\n",
    "# Combine all complexities into a single dictionary\n",
    "combined_complexities = combine_complexities(merged_json)\n",
    "print(\"\\nCombined Complexities:\")\n",
    "print(json.dumps(combined_complexities, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(jsp):\n",
    "    return  dict({**combine_programming_languages(merge_json(jsp)),**combine_complexities(merge_json(jsp))})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa23b948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 6.1875,\n",
       " 'C++': 6.1875,\n",
       " 'Java': 7.375,\n",
       " 'Python': 9.0,\n",
       " 'R': 7.375,\n",
       " 'Go': 6.0,\n",
       " 'JavaScript': 8,\n",
       " 'Time Complexity': 8.375,\n",
       " 'Space Complexity': 7.0625,\n",
       " 'Overall Technical Complexity': 7.25}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(jsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45abf2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66392e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04721428",
   "metadata": {},
   "outputs": [],
   "source": [
    "cod=\"\"\" #include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N_STATES 10\n",
    "#define N_ACTIONS 4\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[N_STATES][N_ACTIONS];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < N_STATES; i++) {\n",
    "    for (int j = 0; j < N_ACTIONS; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (1) {\n",
    "    // Get the current state.\n",
    "    state = rand() % N_STATES;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % N_STATES;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < N_STATES; i++) {\n",
    "      for (int j = 0; j < N_ACTIONS; j++) {\n",
    "        printf(\"%f \", q_table[i][j]);\n",
    "      }\n",
    "      printf(\"\\n\");\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < N_ACTIONS; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "      max_val = arr[i];\n",
    "      max_idx = i;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return max_idx;\n",
    "}\n",
    "\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[10][4];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < 10; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (true) {\n",
    "    // Get the current state.\n",
    "    state = rand() % 10;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % 10;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 4; j++) {\n",
    "        cout << q_table[i][j] << \" \";\n",
    "      }\n",
    "      cout << endl;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < 4; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "public class QLearning {\n",
    "\n",
    "  private int[][] qTable;\n",
    "  private int ALPHA;\n",
    "  private int GAMMA;\n",
    "\n",
    "  public QLearning(int[][] qTable, int alpha, int gamma) {\n",
    "    this.qTable = qTable;\n",
    "    this.ALPHA = alpha;\n",
    "    this.GAMMA = gamma;\n",
    "  }\n",
    "\n",
    "  public void learn(int state, int action, int reward, int nextState) {\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - ALPHA) * qTable[state][action] + ALPHA * (reward + GAMMA * maxQValue(nextState));\n",
    "  }\n",
    "\n",
    "  public int maxQValue(int state) {\n",
    "    int maxQValue = qTable[state][0];\n",
    "    for (int action = 1; action < qTable[state].length; action++) {\n",
    "      if (qTable[state][action] > maxQValue) {\n",
    "        maxQValue = qTable[state][action];\n",
    "      }\n",
    "    }\n",
    "    return maxQValue;\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) {\n",
    "    // Initialize the Q-table\n",
    "    int[][] qTable = new int[10][10];\n",
    "\n",
    "    // Initialize the environment\n",
    "    int state = 0;\n",
    "    int action = 0;\n",
    "    int reward = 0;\n",
    "\n",
    "    // Loop until the agent reaches the goal state\n",
    "    while (state != 9) {\n",
    "      // Choose an action\n",
    "      action = 0;\n",
    "      int maxQValue = qTable[state][0];\n",
    "      for (int i = 1; i < 10; i++) {\n",
    "        if (qTable[state][i] > maxQValue) {\n",
    "          maxQValue = qTable[state][i];\n",
    "          action = i;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Take the action and observe the reward and next state\n",
    "      reward = 1;\n",
    "      state = nextState;\n",
    "\n",
    "      // Update the Q-table\n",
    "      qLearning.learn(state, action, reward, nextState);\n",
    "    }\n",
    "\n",
    "    // Print the Q-table\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 10; j++) {\n",
    "        System.out.print(qTable[i][j] + \" \");\n",
    "      }\n",
    "      System.out.println();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "function qLearning(env, qTable, alpha, gamma) {\n",
    "  state = env.reset();\n",
    "  while (true) {\n",
    "    // Choose an action\n",
    "    action = Math.argmax(qTable[state]);\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done = env.step(action);\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * Math.max(qTable[nextState]));\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "// Initialize the environment\n",
    "env = new FrozenLakeEnv();\n",
    "\n",
    "// Initialize the Q-table\n",
    "qTable = new Array(env.n_states).fill(0);\n",
    "\n",
    "// Initialize the learning rate and discount factor\n",
    "alpha = 0.1;\n",
    "gamma = 0.9;\n",
    "\n",
    "// Train the agent\n",
    "qLearning(env, qTable, alpha, gamma);\n",
    "def q_learning(env, q_table, alpha, gamma):\n",
    "  state = env.reset()\n",
    "  while True:\n",
    "    # Choose an action\n",
    "    action = np.argmax(q_table[state])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    next_state, reward, done = env.step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    q_table[state][action] = (1 - alpha) * q_table[state][action] + alpha * (reward + gamma * np.max(q_table[next_state]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "# Initialize the environment\n",
    "env = FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "q_table = np.zeros((env.n_states, env.n_actions))\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Train the agent\n",
    "q_learning(env, q_table, alpha, gamma)\n",
    "qLearning <- function(env, qTable, alpha, gamma) {\n",
    "  state <- env$reset()\n",
    "  while (TRUE) {\n",
    "    # Choose an action\n",
    "    action <- which.max(qTable[state, ])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    nextState, reward, done <- env$step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    qTable[state, action] <- (1 - alpha) * qTable[state, action] + alpha * (reward + gamma * max(qTable[nextState, ]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state <- nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "# Initialize the environment\n",
    "env <- FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "qTable <- matrix(0, nrow = env$n_states, ncol = env$n_actions)\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha <- 0.1\n",
    "gamma <- 0.9\n",
    "\n",
    "# Train the agent\n",
    "qLearning(env, qTable, alpha, gamma)\n",
    "package main\n",
    "\n",
    "import (\n",
    "  \"fmt\"\n",
    "  \"math/rand\"\n",
    ")\n",
    "\n",
    "func main() {\n",
    "  // Initialize the environment\n",
    "  env := FrozenLakeEnv()\n",
    "\n",
    "  // Initialize the Q-table\n",
    "  qTable := make([][]float64, env.n_states)\n",
    "  for i := range qTable {\n",
    "    qTable[i] = make([]float64, env.n_actions)\n",
    "  }\n",
    "\n",
    "  // Initialize the learning rate and discount factor\n",
    "  alpha := 0.1\n",
    "  gamma := 0.9\n",
    "\n",
    "  // Train the agent\n",
    "  for i := 0; i < 10000; i++ {\n",
    "    // Choose an action\n",
    "    state := env.reset()\n",
    "    action := rand.Intn(env.n_actions)\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done := env.step(action)\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * max(qTable[nextState]))\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if done {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "\n",
    "  // Print the Q-table\n",
    "  for i := 0; i < env.n_states; i++ {\n",
    "    for j := 0; j < env.n_actions; j++ {\n",
    "      fmt.Printf(\"%f \", qTable[i][j])\n",
    "    }\n",
    "    fmt.Println()\n",
    "  }\n",
    "}\n",
    " #include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N_STATES 10\n",
    "#define N_ACTIONS 4\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[N_STATES][N_ACTIONS];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < N_STATES; i++) {\n",
    "    for (int j = 0; j < N_ACTIONS; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (1) {\n",
    "    // Get the current state.\n",
    "    state = rand() % N_STATES;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % N_STATES;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < N_STATES; i++) {\n",
    "      for (int j = 0; j < N_ACTIONS; j++) {\n",
    "        printf(\"%f \", q_table[i][j]);\n",
    "      }\n",
    "      printf(\"\\n\");\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < N_ACTIONS; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "      max_val = arr[i];\n",
    "      max_idx = i;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return max_idx;\n",
    "}\n",
    "\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[10][4];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < 10; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (true) {\n",
    "    // Get the current state.\n",
    "    state = rand() % 10;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % 10;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 4; j++) {\n",
    "        cout << q_table[i][j] << \" \";\n",
    "      }\n",
    "      cout << endl;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < 4; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "public class QLearning {\n",
    "\n",
    "  private int[][] qTable;\n",
    "  private int ALPHA;\n",
    "  private int GAMMA;\n",
    "\n",
    "  public QLearning(int[][] qTable, int alpha, int gamma) {\n",
    "    this.qTable = qTable;\n",
    "    this.ALPHA = alpha;\n",
    "    this.GAMMA = gamma;\n",
    "  }\n",
    "\n",
    "  public void learn(int state, int action, int reward, int nextState) {\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - ALPHA) * qTable[state][action] + ALPHA * (reward + GAMMA * maxQValue(nextState));\n",
    "  }\n",
    "\n",
    "  public int maxQValue(int state) {\n",
    "    int maxQValue = qTable[state][0];\n",
    "    for (int action = 1; action < qTable[state].length; action++) {\n",
    "      if (qTable[state][action] > maxQValue) {\n",
    "        maxQValue = qTable[state][action];\n",
    "      }\n",
    "    }\n",
    "    return maxQValue;\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) {\n",
    "    // Initialize the Q-table\n",
    "    int[][] qTable = new int[10][10];\n",
    "\n",
    "    // Initialize the environment\n",
    "    int state = 0;\n",
    "    int action = 0;\n",
    "    int reward = 0;\n",
    "\n",
    "    // Loop until the agent reaches the goal state\n",
    "    while (state != 9) {\n",
    "      // Choose an action\n",
    "      action = 0;\n",
    "      int maxQValue = qTable[state][0];\n",
    "      for (int i = 1; i < 10; i++) {\n",
    "        if (qTable[state][i] > maxQValue) {\n",
    "          maxQValue = qTable[state][i];\n",
    "          action = i;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Take the action and observe the reward and next state\n",
    "      reward = 1;\n",
    "      state = nextState;\n",
    "\n",
    "      // Update the Q-table\n",
    "      qLearning.learn(state, action, reward, nextState);\n",
    "    }\n",
    "\n",
    "    // Print the Q-table\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 10; j++) {\n",
    "        System.out.print(qTable[i][j] + \" \");\n",
    "      }\n",
    "      System.out.println();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "function qLearning(env, qTable, alpha, gamma) {\n",
    "  state = env.reset();\n",
    "  while (true) {\n",
    "    // Choose an action\n",
    "    action = Math.argmax(qTable[state]);\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done = env.step(action);\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * Math.max(qTable[nextState]));\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "// Initialize the environment\n",
    "env = new FrozenLakeEnv();\n",
    "\n",
    "// Initialize the Q-table\n",
    "qTable = new Array(env.n_states).fill(0);\n",
    "\n",
    "// Initialize the learning rate and discount factor\n",
    "alpha = 0.1;\n",
    "gamma = 0.9;\n",
    "\n",
    "// Train the agent\n",
    "qLearning(env, qTable, alpha, gamma);\n",
    "def q_learning(env, q_table, alpha, gamma):\n",
    "  state = env.reset()\n",
    "  while True:\n",
    "    # Choose an action\n",
    "    action = np.argmax(q_table[state])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    next_state, reward, done = env.step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    q_table[state][action] = (1 - alpha) * q_table[state][action] + alpha * (reward + gamma * np.max(q_table[next_state]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "# Initialize the environment\n",
    "env = FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "q_table = np.zeros((env.n_states, env.n_actions))\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Train the agent\n",
    "q_learning(env, q_table, alpha, gamma)\n",
    "qLearning <- function(env, qTable, alpha, gamma) {\n",
    "  state <- env$reset()\n",
    "  while (TRUE) {\n",
    "    # Choose an action\n",
    "    action <- which.max(qTable[state, ])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    nextState, reward, done <- env$step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    qTable[state, action] <- (1 - alpha) * qTable[state, action] + alpha * (reward + gamma * max(qTable[nextState, ]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state <- nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "# Initialize the environment\n",
    "env <- FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "qTable <- matrix(0, nrow = env$n_states, ncol = env$n_actions)\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha <- 0.1\n",
    "gamma <- 0.9\n",
    "\n",
    "# Train the agent\n",
    "qLearning(env, qTable, alpha, gamma)\n",
    "package main\n",
    "\n",
    "import (\n",
    "  \"fmt\"\n",
    "  \"math/rand\"\n",
    ")\n",
    "\n",
    "func main() {\n",
    "  // Initialize the environment\n",
    "  env := FrozenLakeEnv()\n",
    "\n",
    "  // Initialize the Q-table\n",
    "  qTable := make([][]float64, env.n_states)\n",
    "  for i := range qTable {\n",
    "    qTable[i] = make([]float64, env.n_actions)\n",
    "  }\n",
    "\n",
    "  // Initialize the learning rate and discount factor\n",
    "  alpha := 0.1\n",
    "  gamma := 0.9\n",
    "\n",
    "  // Train the agent\n",
    "  for i := 0; i < 10000; i++ {\n",
    "    // Choose an action\n",
    "    state := env.reset()\n",
    "    action := rand.Intn(env.n_actions)\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done := env.step(action)\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * max(qTable[nextState]))\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if done {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "\n",
    "  // Print the Q-table\n",
    "  for i := 0; i < env.n_states; i++ {\n",
    "    for j := 0; j < env.n_actions; j++ {\n",
    "      fmt.Printf(\"%f \", qTable[i][j])\n",
    "    }\n",
    "    fmt.Println()\n",
    "  }\n",
    "}\n",
    " #include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N_STATES 10\n",
    "#define N_ACTIONS 4\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[N_STATES][N_ACTIONS];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < N_STATES; i++) {\n",
    "    for (int j = 0; j < N_ACTIONS; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (1) {\n",
    "    // Get the current state.\n",
    "    state = rand() % N_STATES;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % N_STATES;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < N_STATES; i++) {\n",
    "      for (int j = 0; j < N_ACTIONS; j++) {\n",
    "        printf(\"%f \", q_table[i][j]);\n",
    "      }\n",
    "      printf(\"\\n\");\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < N_ACTIONS; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "      max_val = arr[i];\n",
    "      max_idx = i;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return max_idx;\n",
    "}\n",
    "\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[10][4];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < 10; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (true) {\n",
    "    // Get the current state.\n",
    "    state = rand() % 10;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % 10;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 4; j++) {\n",
    "        cout << q_table[i][j] << \" \";\n",
    "      }\n",
    "      cout << endl;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < 4; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "public class QLearning {\n",
    "\n",
    "  private int[][] qTable;\n",
    "  private int ALPHA;\n",
    "  private int GAMMA;\n",
    "\n",
    "  public QLearning(int[][] qTable, int alpha, int gamma) {\n",
    "    this.qTable = qTable;\n",
    "    this.ALPHA = alpha;\n",
    "    this.GAMMA = gamma;\n",
    "  }\n",
    "\n",
    "  public void learn(int state, int action, int reward, int nextState) {\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - ALPHA) * qTable[state][action] + ALPHA * (reward + GAMMA * maxQValue(nextState));\n",
    "  }\n",
    "\n",
    "  public int maxQValue(int state) {\n",
    "    int maxQValue = qTable[state][0];\n",
    "    for (int action = 1; action < qTable[state].length; action++) {\n",
    "      if (qTable[state][action] > maxQValue) {\n",
    "        maxQValue = qTable[state][action];\n",
    "      }\n",
    "    }\n",
    "    return maxQValue;\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) {\n",
    "    // Initialize the Q-table\n",
    "    int[][] qTable = new int[10][10];\n",
    "\n",
    "    // Initialize the environment\n",
    "    int state = 0;\n",
    "    int action = 0;\n",
    "    int reward = 0;\n",
    "\n",
    "    // Loop until the agent reaches the goal state\n",
    "    while (state != 9) {\n",
    "      // Choose an action\n",
    "      action = 0;\n",
    "      int maxQValue = qTable[state][0];\n",
    "      for (int i = 1; i < 10; i++) {\n",
    "        if (qTable[state][i] > maxQValue) {\n",
    "          maxQValue = qTable[state][i];\n",
    "          action = i;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Take the action and observe the reward and next state\n",
    "      reward = 1;\n",
    "      state = nextState;\n",
    "\n",
    "      // Update the Q-table\n",
    "      qLearning.learn(state, action, reward, nextState);\n",
    "    }\n",
    "\n",
    "    // Print the Q-table\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 10; j++) {\n",
    "        System.out.print(qTable[i][j] + \" \");\n",
    "      }\n",
    "      System.out.println();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "function qLearning(env, qTable, alpha, gamma) {\n",
    "  state = env.reset();\n",
    "  while (true) {\n",
    "    // Choose an action\n",
    "    action = Math.argmax(qTable[state]);\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done = env.step(action);\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * Math.max(qTable[nextState]));\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "// Initialize the environment\n",
    "env = new FrozenLakeEnv();\n",
    "\n",
    "// Initialize the Q-table\n",
    "qTable = new Array(env.n_states).fill(0);\n",
    "\n",
    "// Initialize the learning rate and discount factor\n",
    "alpha = 0.1;\n",
    "gamma = 0.9;\n",
    "\n",
    "// Train the agent\n",
    "qLearning(env, qTable, alpha, gamma);\n",
    "def q_learning(env, q_table, alpha, gamma):\n",
    "  state = env.reset()\n",
    "  while True:\n",
    "    # Choose an action\n",
    "    action = np.argmax(q_table[state])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    next_state, reward, done = env.step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    q_table[state][action] = (1 - alpha) * q_table[state][action] + alpha * (reward + gamma * np.max(q_table[next_state]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "# Initialize the environment\n",
    "env = FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "q_table = np.zeros((env.n_states, env.n_actions))\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Train the agent\n",
    "q_learning(env, q_table, alpha, gamma)\n",
    "qLearning <- function(env, qTable, alpha, gamma) {\n",
    "  state <- env$reset()\n",
    "  while (TRUE) {\n",
    "    # Choose an action\n",
    "    action <- which.max(qTable[state, ])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    nextState, reward, done <- env$step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    qTable[state, action] <- (1 - alpha) * qTable[state, action] + alpha * (reward + gamma * max(qTable[nextState, ]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state <- nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "# Initialize the environment\n",
    "env <- FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "qTable <- matrix(0, nrow = env$n_states, ncol = env$n_actions)\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha <- 0.1\n",
    "gamma <- 0.9\n",
    "\n",
    "# Train the agent\n",
    "qLearning(env, qTable, alpha, gamma)\n",
    "package main\n",
    "\n",
    "import (\n",
    "  \"fmt\"\n",
    "  \"math/rand\"\n",
    ")\n",
    "\n",
    "func main() {\n",
    "  // Initialize the environment\n",
    "  env := FrozenLakeEnv()\n",
    "\n",
    "  // Initialize the Q-table\n",
    "  qTable := make([][]float64, env.n_states)\n",
    "  for i := range qTable {\n",
    "    qTable[i] = make([]float64, env.n_actions)\n",
    "  }\n",
    "\n",
    "  // Initialize the learning rate and discount factor\n",
    "  alpha := 0.1\n",
    "  gamma := 0.9\n",
    "\n",
    "  // Train the agent\n",
    "  for i := 0; i < 10000; i++ {\n",
    "    // Choose an action\n",
    "    state := env.reset()\n",
    "    action := rand.Intn(env.n_actions)\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done := env.step(action)\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * max(qTable[nextState]))\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if done {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "\n",
    "  // Print the Q-table\n",
    "  for i := 0; i < env.n_states; i++ {\n",
    "    for j := 0; j < env.n_actions; j++ {\n",
    "      fmt.Printf(\"%f \", qTable[i][j])\n",
    "    }\n",
    "    fmt.Println()\n",
    "  }\n",
    "}\n",
    " #include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N_STATES 10\n",
    "#define N_ACTIONS 4\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[N_STATES][N_ACTIONS];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < N_STATES; i++) {\n",
    "    for (int j = 0; j < N_ACTIONS; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (1) {\n",
    "    // Get the current state.\n",
    "    state = rand() % N_STATES;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % N_STATES;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < N_STATES; i++) {\n",
    "      for (int j = 0; j < N_ACTIONS; j++) {\n",
    "        printf(\"%f \", q_table[i][j]);\n",
    "      }\n",
    "      printf(\"\\n\");\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < N_ACTIONS; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "      max_val = arr[i];\n",
    "      max_idx = i;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return max_idx;\n",
    "}\n",
    "\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[10][4];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < 10; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (true) {\n",
    "    // Get the current state.\n",
    "    state = rand() % 10;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % 10;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 4; j++) {\n",
    "        cout << q_table[i][j] << \" \";\n",
    "      }\n",
    "      cout << endl;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < 4; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "public class QLearning {\n",
    "\n",
    "  private int[][] qTable;\n",
    "  private int ALPHA;\n",
    "  private int GAMMA;\n",
    "\n",
    "  public QLearning(int[][] qTable, int alpha, int gamma) {\n",
    "    this.qTable = qTable;\n",
    "    this.ALPHA = alpha;\n",
    "    this.GAMMA = gamma;\n",
    "  }\n",
    "\n",
    "  public void learn(int state, int action, int reward, int nextState) {\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - ALPHA) * qTable[state][action] + ALPHA * (reward + GAMMA * maxQValue(nextState));\n",
    "  }\n",
    "\n",
    "  public int maxQValue(int state) {\n",
    "    int maxQValue = qTable[state][0];\n",
    "    for (int action = 1; action < qTable[state].length; action++) {\n",
    "      if (qTable[state][action] > maxQValue) {\n",
    "        maxQValue = qTable[state][action];\n",
    "      }\n",
    "    }\n",
    "    return maxQValue;\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) {\n",
    "    // Initialize the Q-table\n",
    "    int[][] qTable = new int[10][10];\n",
    "\n",
    "    // Initialize the environment\n",
    "    int state = 0;\n",
    "    int action = 0;\n",
    "    int reward = 0;\n",
    "\n",
    "    // Loop until the agent reaches the goal state\n",
    "    while (state != 9) {\n",
    "      // Choose an action\n",
    "      action = 0;\n",
    "      int maxQValue = qTable[state][0];\n",
    "      for (int i = 1; i < 10; i++) {\n",
    "        if (qTable[state][i] > maxQValue) {\n",
    "          maxQValue = qTable[state][i];\n",
    "          action = i;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Take the action and observe the reward and next state\n",
    "      reward = 1;\n",
    "      state = nextState;\n",
    "\n",
    "      // Update the Q-table\n",
    "      qLearning.learn(state, action, reward, nextState);\n",
    "    }\n",
    "\n",
    "    // Print the Q-table\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 10; j++) {\n",
    "        System.out.print(qTable[i][j] + \" \");\n",
    "      }\n",
    "      System.out.println();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "function qLearning(env, qTable, alpha, gamma) {\n",
    "  state = env.reset();\n",
    "  while (true) {\n",
    "    // Choose an action\n",
    "    action = Math.argmax(qTable[state]);\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done = env.step(action);\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * Math.max(qTable[nextState]));\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "// Initialize the environment\n",
    "env = new FrozenLakeEnv();\n",
    "\n",
    "// Initialize the Q-table\n",
    "qTable = new Array(env.n_states).fill(0);\n",
    "\n",
    "// Initialize the learning rate and discount factor\n",
    "alpha = 0.1;\n",
    "gamma = 0.9;\n",
    "\n",
    "// Train the agent\n",
    "qLearning(env, qTable, alpha, gamma);\n",
    "def q_learning(env, q_table, alpha, gamma):\n",
    "  state = env.reset()\n",
    "  while True:\n",
    "    # Choose an action\n",
    "    action = np.argmax(q_table[state])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    next_state, reward, done = env.step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    q_table[state][action] = (1 - alpha) * q_table[state][action] + alpha * (reward + gamma * np.max(q_table[next_state]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "# Initialize the environment\n",
    "env = FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "q_table = np.zeros((env.n_states, env.n_actions))\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Train the agent\n",
    "q_learning(env, q_table, alpha, gamma)\n",
    "qLearning <- function(env, qTable, alpha, gamma) {\n",
    "  state <- env$reset()\n",
    "  while (TRUE) {\n",
    "    # Choose an action\n",
    "    action <- which.max(qTable[state, ])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    nextState, reward, done <- env$step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    qTable[state, action] <- (1 - alpha) * qTable[state, action] + alpha * (reward + gamma * max(qTable[nextState, ]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state <- nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "# Initialize the environment\n",
    "env <- FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "qTable <- matrix(0, nrow = env$n_states, ncol = env$n_actions)\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha <- 0.1\n",
    "gamma <- 0.9\n",
    "\n",
    "# Train the agent\n",
    "qLearning(env, qTable, alpha, gamma)\n",
    "package main\n",
    "\n",
    "import (\n",
    "  \"fmt\"\n",
    "  \"math/rand\"\n",
    ")\n",
    "\n",
    "func main() {\n",
    "  // Initialize the environment\n",
    "  env := FrozenLakeEnv()\n",
    "\n",
    "  // Initialize the Q-table\n",
    "  qTable := make([][]float64, env.n_states)\n",
    "  for i := range qTable {\n",
    "    qTable[i] = make([]float64, env.n_actions)\n",
    "  }\n",
    "\n",
    "  // Initialize the learning rate and discount factor\n",
    "  alpha := 0.1\n",
    "  gamma := 0.9\n",
    "\n",
    "  // Train the agent\n",
    "  for i := 0; i < 10000; i++ {\n",
    "    // Choose an action\n",
    "    state := env.reset()\n",
    "    action := rand.Intn(env.n_actions)\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done := env.step(action)\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * max(qTable[nextState]))\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if done {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "\n",
    "  // Print the Q-table\n",
    "  for i := 0; i < env.n_states; i++ {\n",
    "    for j := 0; j < env.n_actions; j++ {\n",
    "      fmt.Printf(\"%f \", qTable[i][j])\n",
    "    }\n",
    "    fmt.Println()\n",
    "  }\n",
    "}\n",
    " #include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N_STATES 10\n",
    "#define N_ACTIONS 4\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[N_STATES][N_ACTIONS];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < N_STATES; i++) {\n",
    "    for (int j = 0; j < N_ACTIONS; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (1) {\n",
    "    // Get the current state.\n",
    "    state = rand() % N_STATES;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % N_STATES;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < N_STATES; i++) {\n",
    "      for (int j = 0; j < N_ACTIONS; j++) {\n",
    "        printf(\"%f \", q_table[i][j]);\n",
    "      }\n",
    "      printf(\"\\n\");\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < N_ACTIONS; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "      max_val = arr[i];\n",
    "      max_idx = i;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return max_idx;\n",
    "}\n",
    "\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[10][4];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < 10; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (true) {\n",
    "    // Get the current state.\n",
    "    state = rand() % 10;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % 10;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 4; j++) {\n",
    "        cout << q_table[i][j] << \" \";\n",
    "      }\n",
    "      cout << endl;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < 4; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "public class QLearning {\n",
    "\n",
    "  private int[][] qTable;\n",
    "  private int ALPHA;\n",
    "  private int GAMMA;\n",
    "\n",
    "  public QLearning(int[][] qTable, int alpha, int gamma) {\n",
    "    this.qTable = qTable;\n",
    "    this.ALPHA = alpha;\n",
    "    this.GAMMA = gamma;\n",
    "  }\n",
    "\n",
    "  public void learn(int state, int action, int reward, int nextState) {\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - ALPHA) * qTable[state][action] + ALPHA * (reward + GAMMA * maxQValue(nextState));\n",
    "  }\n",
    "\n",
    "  public int maxQValue(int state) {\n",
    "    int maxQValue = qTable[state][0];\n",
    "    for (int action = 1; action < qTable[state].length; action++) {\n",
    "      if (qTable[state][action] > maxQValue) {\n",
    "        maxQValue = qTable[state][action];\n",
    "      }\n",
    "    }\n",
    "    return maxQValue;\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) {\n",
    "    // Initialize the Q-table\n",
    "    int[][] qTable = new int[10][10];\n",
    "\n",
    "    // Initialize the environment\n",
    "    int state = 0;\n",
    "    int action = 0;\n",
    "    int reward = 0;\n",
    "\n",
    "    // Loop until the agent reaches the goal state\n",
    "    while (state != 9) {\n",
    "      // Choose an action\n",
    "      action = 0;\n",
    "      int maxQValue = qTable[state][0];\n",
    "      for (int i = 1; i < 10; i++) {\n",
    "        if (qTable[state][i] > maxQValue) {\n",
    "          maxQValue = qTable[state][i];\n",
    "          action = i;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Take the action and observe the reward and next state\n",
    "      reward = 1;\n",
    "      state = nextState;\n",
    "\n",
    "      // Update the Q-table\n",
    "      qLearning.learn(state, action, reward, nextState);\n",
    "    }\n",
    "\n",
    "    // Print the Q-table\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 10; j++) {\n",
    "        System.out.print(qTable[i][j] + \" \");\n",
    "      }\n",
    "      System.out.println();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "function qLearning(env, qTable, alpha, gamma) {\n",
    "  state = env.reset();\n",
    "  while (true) {\n",
    "    // Choose an action\n",
    "    action = Math.argmax(qTable[state]);\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done = env.step(action);\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * Math.max(qTable[nextState]));\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "// Initialize the environment\n",
    "env = new FrozenLakeEnv();\n",
    "\n",
    "// Initialize the Q-table\n",
    "qTable = new Array(env.n_states).fill(0);\n",
    "\n",
    "// Initialize the learning rate and discount factor\n",
    "alpha = 0.1;\n",
    "gamma = 0.9;\n",
    "\n",
    "// Train the agent\n",
    "qLearning(env, qTable, alpha, gamma);\n",
    "def q_learning(env, q_table, alpha, gamma):\n",
    "  state = env.reset()\n",
    "  while True:\n",
    "    # Choose an action\n",
    "    action = np.argmax(q_table[state])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    next_state, reward, done = env.step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    q_table[state][action] = (1 - alpha) * q_table[state][action] + alpha * (reward + gamma * np.max(q_table[next_state]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "# Initialize the environment\n",
    "env = FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "q_table = np.zeros((env.n_states, env.n_actions))\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Train the agent\n",
    "q_learning(env, q_table, alpha, gamma)\n",
    "qLearning <- function(env, qTable, alpha, gamma) {\n",
    "  state <- env$reset()\n",
    "  while (TRUE) {\n",
    "    # Choose an action\n",
    "    action <- which.max(qTable[state, ])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    nextState, reward, done <- env$step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    qTable[state, action] <- (1 - alpha) * qTable[state, action] + alpha * (reward + gamma * max(qTable[nextState, ]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state <- nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "# Initialize the environment\n",
    "env <- FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "qTable <- matrix(0, nrow = env$n_states, ncol = env$n_actions)\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha <- 0.1\n",
    "gamma <- 0.9\n",
    "\n",
    "# Train the agent\n",
    "qLearning(env, qTable, alpha, gamma)\n",
    "package main\n",
    "\n",
    "import (\n",
    "  \"fmt\"\n",
    "  \"math/rand\"\n",
    ")\n",
    "\n",
    "func main() {\n",
    "  // Initialize the environment\n",
    "  env := FrozenLakeEnv()\n",
    "\n",
    "  // Initialize the Q-table\n",
    "  qTable := make([][]float64, env.n_states)\n",
    "  for i := range qTable {\n",
    "    qTable[i] = make([]float64, env.n_actions)\n",
    "  }\n",
    "\n",
    "  // Initialize the learning rate and discount factor\n",
    "  alpha := 0.1\n",
    "  gamma := 0.9\n",
    "\n",
    "  // Train the agent\n",
    "  for i := 0; i < 10000; i++ {\n",
    "    // Choose an action\n",
    "    state := env.reset()\n",
    "    action := rand.Intn(env.n_actions)\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done := env.step(action)\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * max(qTable[nextState]))\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if done {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "\n",
    "  // Print the Q-table\n",
    "  for i := 0; i < env.n_states; i++ {\n",
    "    for j := 0; j < env.n_actions; j++ {\n",
    "      fmt.Printf(\"%f \", qTable[i][j])\n",
    "    }\n",
    "    fmt.Println()\n",
    "  }\n",
    "}\n",
    " #include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N_STATES 10\n",
    "#define N_ACTIONS 4\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[N_STATES][N_ACTIONS];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < N_STATES; i++) {\n",
    "    for (int j = 0; j < N_ACTIONS; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (1) {\n",
    "    // Get the current state.\n",
    "    state = rand() % N_STATES;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % N_STATES;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < N_STATES; i++) {\n",
    "      for (int j = 0; j < N_ACTIONS; j++) {\n",
    "        printf(\"%f \", q_table[i][j]);\n",
    "      }\n",
    "      printf(\"\\n\");\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < N_ACTIONS; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "      max_val = arr[i];\n",
    "      max_idx = i;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return max_idx;\n",
    "}\n",
    "\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[10][4];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < 10; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (true) {\n",
    "    // Get the current state.\n",
    "    state = rand() % 10;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % 10;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 4; j++) {\n",
    "        cout << q_table[i][j] << \" \";\n",
    "      }\n",
    "      cout << endl;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < 4; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "public class QLearning {\n",
    "\n",
    "  private int[][] qTable;\n",
    "  private int ALPHA;\n",
    "  private int GAMMA;\n",
    "\n",
    "  public QLearning(int[][] qTable, int alpha, int gamma) {\n",
    "    this.qTable = qTable;\n",
    "    this.ALPHA = alpha;\n",
    "    this.GAMMA = gamma;\n",
    "  }\n",
    "\n",
    "  public void learn(int state, int action, int reward, int nextState) {\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - ALPHA) * qTable[state][action] + ALPHA * (reward + GAMMA * maxQValue(nextState));\n",
    "  }\n",
    "\n",
    "  public int maxQValue(int state) {\n",
    "    int maxQValue = qTable[state][0];\n",
    "    for (int action = 1; action < qTable[state].length; action++) {\n",
    "      if (qTable[state][action] > maxQValue) {\n",
    "        maxQValue = qTable[state][action];\n",
    "      }\n",
    "    }\n",
    "    return maxQValue;\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) {\n",
    "    // Initialize the Q-table\n",
    "    int[][] qTable = new int[10][10];\n",
    "\n",
    "    // Initialize the environment\n",
    "    int state = 0;\n",
    "    int action = 0;\n",
    "    int reward = 0;\n",
    "\n",
    "    // Loop until the agent reaches the goal state\n",
    "    while (state != 9) {\n",
    "      // Choose an action\n",
    "      action = 0;\n",
    "      int maxQValue = qTable[state][0];\n",
    "      for (int i = 1; i < 10; i++) {\n",
    "        if (qTable[state][i] > maxQValue) {\n",
    "          maxQValue = qTable[state][i];\n",
    "          action = i;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Take the action and observe the reward and next state\n",
    "      reward = 1;\n",
    "      state = nextState;\n",
    "\n",
    "      // Update the Q-table\n",
    "      qLearning.learn(state, action, reward, nextState);\n",
    "    }\n",
    "\n",
    "    // Print the Q-table\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 10; j++) {\n",
    "        System.out.print(qTable[i][j] + \" \");\n",
    "      }\n",
    "      System.out.println();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "function qLearning(env, qTable, alpha, gamma) {\n",
    "  state = env.reset();\n",
    "  while (true) {\n",
    "    // Choose an action\n",
    "    action = Math.argmax(qTable[state]);\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done = env.step(action);\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * Math.max(qTable[nextState]));\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "// Initialize the environment\n",
    "env = new FrozenLakeEnv();\n",
    "\n",
    "// Initialize the Q-table\n",
    "qTable = new Array(env.n_states).fill(0);\n",
    "\n",
    "// Initialize the learning rate and discount factor\n",
    "alpha = 0.1;\n",
    "gamma = 0.9;\n",
    "\n",
    "// Train the agent\n",
    "qLearning(env, qTable, alpha, gamma);\n",
    "def q_learning(env, q_table, alpha, gamma):\n",
    "  state = env.reset()\n",
    "  while True:\n",
    "    # Choose an action\n",
    "    action = np.argmax(q_table[state])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    next_state, reward, done = env.step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    q_table[state][action] = (1 - alpha) * q_table[state][action] + alpha * (reward + gamma * np.max(q_table[next_state]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "# Initialize the environment\n",
    "env = FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "q_table = np.zeros((env.n_states, env.n_actions))\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Train the agent\n",
    "q_learning(env, q_table, alpha, gamma)\n",
    "qLearning <- function(env, qTable, alpha, gamma) {\n",
    "  state <- env$reset()\n",
    "  while (TRUE) {\n",
    "    # Choose an action\n",
    "    action <- which.max(qTable[state, ])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    nextState, reward, done <- env$step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    qTable[state, action] <- (1 - alpha) * qTable[state, action] + alpha * (reward + gamma * max(qTable[nextState, ]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state <- nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "# Initialize the environment\n",
    "env <- FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "qTable <- matrix(0, nrow = env$n_states, ncol = env$n_actions)\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha <- 0.1\n",
    "gamma <- 0.9\n",
    "\n",
    "# Train the agent\n",
    "qLearning(env, qTable, alpha, gamma)\n",
    "package main\n",
    "\n",
    "import (\n",
    "  \"fmt\"\n",
    "  \"math/rand\"\n",
    ")\n",
    "\n",
    "func main() {\n",
    "  // Initialize the environment\n",
    "  env := FrozenLakeEnv()\n",
    "\n",
    "  // Initialize the Q-table\n",
    "  qTable := make([][]float64, env.n_states)\n",
    "  for i := range qTable {\n",
    "    qTable[i] = make([]float64, env.n_actions)\n",
    "  }\n",
    "\n",
    "  // Initialize the learning rate and discount factor\n",
    "  alpha := 0.1\n",
    "  gamma := 0.9\n",
    "\n",
    "  // Train the agent\n",
    "  for i := 0; i < 10000; i++ {\n",
    "    // Choose an action\n",
    "    state := env.reset()\n",
    "    action := rand.Intn(env.n_actions)\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done := env.step(action)\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * max(qTable[nextState]))\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if done {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "\n",
    "  // Print the Q-table\n",
    "  for i := 0; i < env.n_states; i++ {\n",
    "    for j := 0; j < env.n_actions; j++ {\n",
    "      fmt.Printf(\"%f \", qTable[i][j])\n",
    "    }\n",
    "    fmt.Println()\n",
    "  }\n",
    "}\n",
    " #include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N_STATES 10\n",
    "#define N_ACTIONS 4\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[N_STATES][N_ACTIONS];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < N_STATES; i++) {\n",
    "    for (int j = 0; j < N_ACTIONS; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (1) {\n",
    "    // Get the current state.\n",
    "    state = rand() % N_STATES;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % N_STATES;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < N_STATES; i++) {\n",
    "      for (int j = 0; j < N_ACTIONS; j++) {\n",
    "        printf(\"%f \", q_table[i][j]);\n",
    "      }\n",
    "      printf(\"\\n\");\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < N_ACTIONS; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "      max_val = arr[i];\n",
    "      max_idx = i;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return max_idx;\n",
    "}\n",
    "\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[10][4];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < 10; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (true) {\n",
    "    // Get the current state.\n",
    "    state = rand() % 10;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % 10;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 4; j++) {\n",
    "        cout << q_table[i][j] << \" \";\n",
    "      }\n",
    "      cout << endl;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < 4; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "public class QLearning {\n",
    "\n",
    "  private int[][] qTable;\n",
    "  private int ALPHA;\n",
    "  private int GAMMA;\n",
    "\n",
    "  public QLearning(int[][] qTable, int alpha, int gamma) {\n",
    "    this.qTable = qTable;\n",
    "    this.ALPHA = alpha;\n",
    "    this.GAMMA = gamma;\n",
    "  }\n",
    "\n",
    "  public void learn(int state, int action, int reward, int nextState) {\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - ALPHA) * qTable[state][action] + ALPHA * (reward + GAMMA * maxQValue(nextState));\n",
    "  }\n",
    "\n",
    "  public int maxQValue(int state) {\n",
    "    int maxQValue = qTable[state][0];\n",
    "    for (int action = 1; action < qTable[state].length; action++) {\n",
    "      if (qTable[state][action] > maxQValue) {\n",
    "        maxQValue = qTable[state][action];\n",
    "      }\n",
    "    }\n",
    "    return maxQValue;\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) {\n",
    "    // Initialize the Q-table\n",
    "    int[][] qTable = new int[10][10];\n",
    "\n",
    "    // Initialize the environment\n",
    "    int state = 0;\n",
    "    int action = 0;\n",
    "    int reward = 0;\n",
    "\n",
    "    // Loop until the agent reaches the goal state\n",
    "    while (state != 9) {\n",
    "      // Choose an action\n",
    "      action = 0;\n",
    "      int maxQValue = qTable[state][0];\n",
    "      for (int i = 1; i < 10; i++) {\n",
    "        if (qTable[state][i] > maxQValue) {\n",
    "          maxQValue = qTable[state][i];\n",
    "          action = i;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Take the action and observe the reward and next state\n",
    "      reward = 1;\n",
    "      state = nextState;\n",
    "\n",
    "      // Update the Q-table\n",
    "      qLearning.learn(state, action, reward, nextState);\n",
    "    }\n",
    "\n",
    "    // Print the Q-table\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 10; j++) {\n",
    "        System.out.print(qTable[i][j] + \" \");\n",
    "      }\n",
    "      System.out.println();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "function qLearning(env, qTable, alpha, gamma) {\n",
    "  state = env.reset();\n",
    "  while (true) {\n",
    "    // Choose an action\n",
    "    action = Math.argmax(qTable[state]);\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done = env.step(action);\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * Math.max(qTable[nextState]));\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "// Initialize the environment\n",
    "env = new FrozenLakeEnv();\n",
    "\n",
    "// Initialize the Q-table\n",
    "qTable = new Array(env.n_states).fill(0);\n",
    "\n",
    "// Initialize the learning rate and discount factor\n",
    "alpha = 0.1;\n",
    "gamma = 0.9;\n",
    "\n",
    "// Train the agent\n",
    "qLearning(env, qTable, alpha, gamma);\n",
    "def q_learning(env, q_table, alpha, gamma):\n",
    "  state = env.reset()\n",
    "  while True:\n",
    "    # Choose an action\n",
    "    action = np.argmax(q_table[state])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    next_state, reward, done = env.step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    q_table[state][action] = (1 - alpha) * q_table[state][action] + alpha * (reward + gamma * np.max(q_table[next_state]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "# Initialize the environment\n",
    "env = FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "q_table = np.zeros((env.n_states, env.n_actions))\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Train the agent\n",
    "q_learning(env, q_table, alpha, gamma)\n",
    "qLearning <- function(env, qTable, alpha, gamma) {\n",
    "  state <- env$reset()\n",
    "  while (TRUE) {\n",
    "    # Choose an action\n",
    "    action <- which.max(qTable[state, ])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    nextState, reward, done <- env$step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    qTable[state, action] <- (1 - alpha) * qTable[state, action] + alpha * (reward + gamma * max(qTable[nextState, ]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state <- nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "# Initialize the environment\n",
    "env <- FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "qTable <- matrix(0, nrow = env$n_states, ncol = env$n_actions)\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha <- 0.1\n",
    "gamma <- 0.9\n",
    "\n",
    "# Train the agent\n",
    "qLearning(env, qTable, alpha, gamma)\n",
    "package main\n",
    "\n",
    "import (\n",
    "  \"fmt\"\n",
    "  \"math/rand\"\n",
    ")\n",
    "\n",
    "func main() {\n",
    "  // Initialize the environment\n",
    "  env := FrozenLakeEnv()\n",
    "\n",
    "  // Initialize the Q-table\n",
    "  qTable := make([][]float64, env.n_states)\n",
    "  for i := range qTable {\n",
    "    qTable[i] = make([]float64, env.n_actions)\n",
    "  }\n",
    "\n",
    "  // Initialize the learning rate and discount factor\n",
    "  alpha := 0.1\n",
    "  gamma := 0.9\n",
    "\n",
    "  // Train the agent\n",
    "  for i := 0; i < 10000; i++ {\n",
    "    // Choose an action\n",
    "    state := env.reset()\n",
    "    action := rand.Intn(env.n_actions)\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done := env.step(action)\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * max(qTable[nextState]))\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if done {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "\n",
    "  // Print the Q-table\n",
    "  for i := 0; i < env.n_states; i++ {\n",
    "    for j := 0; j < env.n_actions; j++ {\n",
    "      fmt.Printf(\"%f \", qTable[i][j])\n",
    "    }\n",
    "    fmt.Println()\n",
    "  }\n",
    "}\n",
    " #include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N_STATES 10\n",
    "#define N_ACTIONS 4\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[N_STATES][N_ACTIONS];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < N_STATES; i++) {\n",
    "    for (int j = 0; j < N_ACTIONS; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (1) {\n",
    "    // Get the current state.\n",
    "    state = rand() % N_STATES;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % N_STATES;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < N_STATES; i++) {\n",
    "      for (int j = 0; j < N_ACTIONS; j++) {\n",
    "        printf(\"%f \", q_table[i][j]);\n",
    "      }\n",
    "      printf(\"\\n\");\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < N_ACTIONS; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "      max_val = arr[i];\n",
    "      max_idx = i;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return max_idx;\n",
    "}\n",
    "\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[10][4];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < 10; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (true) {\n",
    "    // Get the current state.\n",
    "    state = rand() % 10;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % 10;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 4; j++) {\n",
    "        cout << q_table[i][j] << \" \";\n",
    "      }\n",
    "      cout << endl;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < 4; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "public class QLearning {\n",
    "\n",
    "  private int[][] qTable;\n",
    "  private int ALPHA;\n",
    "  private int GAMMA;\n",
    "\n",
    "  public QLearning(int[][] qTable, int alpha, int gamma) {\n",
    "    this.qTable = qTable;\n",
    "    this.ALPHA = alpha;\n",
    "    this.GAMMA = gamma;\n",
    "  }\n",
    "\n",
    "  public void learn(int state, int action, int reward, int nextState) {\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - ALPHA) * qTable[state][action] + ALPHA * (reward + GAMMA * maxQValue(nextState));\n",
    "  }\n",
    "\n",
    "  public int maxQValue(int state) {\n",
    "    int maxQValue = qTable[state][0];\n",
    "    for (int action = 1; action < qTable[state].length; action++) {\n",
    "      if (qTable[state][action] > maxQValue) {\n",
    "        maxQValue = qTable[state][action];\n",
    "      }\n",
    "    }\n",
    "    return maxQValue;\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) {\n",
    "    // Initialize the Q-table\n",
    "    int[][] qTable = new int[10][10];\n",
    "\n",
    "    // Initialize the environment\n",
    "    int state = 0;\n",
    "    int action = 0;\n",
    "    int reward = 0;\n",
    "\n",
    "    // Loop until the agent reaches the goal state\n",
    "    while (state != 9) {\n",
    "      // Choose an action\n",
    "      action = 0;\n",
    "      int maxQValue = qTable[state][0];\n",
    "      for (int i = 1; i < 10; i++) {\n",
    "        if (qTable[state][i] > maxQValue) {\n",
    "          maxQValue = qTable[state][i];\n",
    "          action = i;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Take the action and observe the reward and next state\n",
    "      reward = 1;\n",
    "      state = nextState;\n",
    "\n",
    "      // Update the Q-table\n",
    "      qLearning.learn(state, action, reward, nextState);\n",
    "    }\n",
    "\n",
    "    // Print the Q-table\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 10; j++) {\n",
    "        System.out.print(qTable[i][j] + \" \");\n",
    "      }\n",
    "      System.out.println();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "function qLearning(env, qTable, alpha, gamma) {\n",
    "  state = env.reset();\n",
    "  while (true) {\n",
    "    // Choose an action\n",
    "    action = Math.argmax(qTable[state]);\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done = env.step(action);\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * Math.max(qTable[nextState]));\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "// Initialize the environment\n",
    "env = new FrozenLakeEnv();\n",
    "\n",
    "// Initialize the Q-table\n",
    "qTable = new Array(env.n_states).fill(0);\n",
    "\n",
    "// Initialize the learning rate and discount factor\n",
    "alpha = 0.1;\n",
    "gamma = 0.9;\n",
    "\n",
    "// Train the agent\n",
    "qLearning(env, qTable, alpha, gamma);\n",
    "def q_learning(env, q_table, alpha, gamma):\n",
    "  state = env.reset()\n",
    "  while True:\n",
    "    # Choose an action\n",
    "    action = np.argmax(q_table[state])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    next_state, reward, done = env.step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    q_table[state][action] = (1 - alpha) * q_table[state][action] + alpha * (reward + gamma * np.max(q_table[next_state]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "# Initialize the environment\n",
    "env = FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "q_table = np.zeros((env.n_states, env.n_actions))\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Train the agent\n",
    "q_learning(env, q_table, alpha, gamma)\n",
    "qLearning <- function(env, qTable, alpha, gamma) {\n",
    "  state <- env$reset()\n",
    "  while (TRUE) {\n",
    "    # Choose an action\n",
    "    action <- which.max(qTable[state, ])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    nextState, reward, done <- env$step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    qTable[state, action] <- (1 - alpha) * qTable[state, action] + alpha * (reward + gamma * max(qTable[nextState, ]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state <- nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "# Initialize the environment\n",
    "env <- FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "qTable <- matrix(0, nrow = env$n_states, ncol = env$n_actions)\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha <- 0.1\n",
    "gamma <- 0.9\n",
    "\n",
    "# Train the agent\n",
    "qLearning(env, qTable, alpha, gamma)\n",
    "package main\n",
    "\n",
    "import (\n",
    "  \"fmt\"\n",
    "  \"math/rand\"\n",
    ")\n",
    "\n",
    "func main() {\n",
    "  // Initialize the environment\n",
    "  env := FrozenLakeEnv()\n",
    "\n",
    "  // Initialize the Q-table\n",
    "  qTable := make([][]float64, env.n_states)\n",
    "  for i := range qTable {\n",
    "    qTable[i] = make([]float64, env.n_actions)\n",
    "  }\n",
    "\n",
    "  // Initialize the learning rate and discount factor\n",
    "  alpha := 0.1\n",
    "  gamma := 0.9\n",
    "\n",
    "  // Train the agent\n",
    "  for i := 0; i < 10000; i++ {\n",
    "    // Choose an action\n",
    "    state := env.reset()\n",
    "    action := rand.Intn(env.n_actions)\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done := env.step(action)\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * max(qTable[nextState]))\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if done {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "\n",
    "  // Print the Q-table\n",
    "  for i := 0; i < env.n_states; i++ {\n",
    "    for j := 0; j < env.n_actions; j++ {\n",
    "      fmt.Printf(\"%f \", qTable[i][j])\n",
    "    }\n",
    "    fmt.Println()\n",
    "  }\n",
    "}\n",
    " #include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N_STATES 10\n",
    "#define N_ACTIONS 4\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[N_STATES][N_ACTIONS];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < N_STATES; i++) {\n",
    "    for (int j = 0; j < N_ACTIONS; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (1) {\n",
    "    // Get the current state.\n",
    "    state = rand() % N_STATES;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % N_STATES;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < N_STATES; i++) {\n",
    "      for (int j = 0; j < N_ACTIONS; j++) {\n",
    "        printf(\"%f \", q_table[i][j]);\n",
    "      }\n",
    "      printf(\"\\n\");\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < N_ACTIONS; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "      max_val = arr[i];\n",
    "      max_idx = i;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return max_idx;\n",
    "}\n",
    "\n",
    "#include <iostream>\n",
    "#include <random>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "  int state, action, next_state, reward;\n",
    "  float q_table[10][4];\n",
    "  float gamma = 0.9;\n",
    "  float learning_rate = 0.1;\n",
    "\n",
    "  // Initialize the Q-table with zeros.\n",
    "  for (int i = 0; i < 10; i++) {\n",
    "    for (int j = 0; j < 4; j++) {\n",
    "      q_table[i][j] = 0.0;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Start the reinforcement learning loop.\n",
    "  while (true) {\n",
    "    // Get the current state.\n",
    "    state = rand() % 10;\n",
    "\n",
    "    // Choose an action based on the Q-table.\n",
    "    action = argmax(q_table[state]);\n",
    "\n",
    "    // Take the action and observe the next state and reward.\n",
    "    next_state = rand() % 10;\n",
    "    reward = rand() % 10;\n",
    "\n",
    "    // Update the Q-table.\n",
    "    q_table[state][action] = q_table[state][action] + learning_rate * (reward + gamma * max(q_table[next_state]));\n",
    "\n",
    "    // Print the Q-table.\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 4; j++) {\n",
    "        cout << q_table[i][j] << \" \";\n",
    "      }\n",
    "      cout << endl;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "int argmax(float *arr) {\n",
    "  int i, max_idx = 0;\n",
    "  float max_val = arr[0];\n",
    "\n",
    "  for (i = 1; i < 4; i++) {\n",
    "    if (arr[i] > max_val) {\n",
    "public class QLearning {\n",
    "\n",
    "  private int[][] qTable;\n",
    "  private int ALPHA;\n",
    "  private int GAMMA;\n",
    "\n",
    "  public QLearning(int[][] qTable, int alpha, int gamma) {\n",
    "    this.qTable = qTable;\n",
    "    this.ALPHA = alpha;\n",
    "    this.GAMMA = gamma;\n",
    "  }\n",
    "\n",
    "  public void learn(int state, int action, int reward, int nextState) {\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - ALPHA) * qTable[state][action] + ALPHA * (reward + GAMMA * maxQValue(nextState));\n",
    "  }\n",
    "\n",
    "  public int maxQValue(int state) {\n",
    "    int maxQValue = qTable[state][0];\n",
    "    for (int action = 1; action < qTable[state].length; action++) {\n",
    "      if (qTable[state][action] > maxQValue) {\n",
    "        maxQValue = qTable[state][action];\n",
    "      }\n",
    "    }\n",
    "    return maxQValue;\n",
    "  }\n",
    "\n",
    "  public static void main(String[] args) {\n",
    "    // Initialize the Q-table\n",
    "    int[][] qTable = new int[10][10];\n",
    "\n",
    "    // Initialize the environment\n",
    "    int state = 0;\n",
    "    int action = 0;\n",
    "    int reward = 0;\n",
    "\n",
    "    // Loop until the agent reaches the goal state\n",
    "    while (state != 9) {\n",
    "      // Choose an action\n",
    "      action = 0;\n",
    "      int maxQValue = qTable[state][0];\n",
    "      for (int i = 1; i < 10; i++) {\n",
    "        if (qTable[state][i] > maxQValue) {\n",
    "          maxQValue = qTable[state][i];\n",
    "          action = i;\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // Take the action and observe the reward and next state\n",
    "      reward = 1;\n",
    "      state = nextState;\n",
    "\n",
    "      // Update the Q-table\n",
    "      qLearning.learn(state, action, reward, nextState);\n",
    "    }\n",
    "\n",
    "    // Print the Q-table\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "      for (int j = 0; j < 10; j++) {\n",
    "        System.out.print(qTable[i][j] + \" \");\n",
    "      }\n",
    "      System.out.println();\n",
    "    }\n",
    "  }\n",
    "}\n",
    "function qLearning(env, qTable, alpha, gamma) {\n",
    "  state = env.reset();\n",
    "  while (true) {\n",
    "    // Choose an action\n",
    "    action = Math.argmax(qTable[state]);\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done = env.step(action);\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * Math.max(qTable[nextState]));\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "// Initialize the environment\n",
    "env = new FrozenLakeEnv();\n",
    "\n",
    "// Initialize the Q-table\n",
    "qTable = new Array(env.n_states).fill(0);\n",
    "\n",
    "// Initialize the learning rate and discount factor\n",
    "alpha = 0.1;\n",
    "gamma = 0.9;\n",
    "\n",
    "// Train the agent\n",
    "qLearning(env, qTable, alpha, gamma);\n",
    "def q_learning(env, q_table, alpha, gamma):\n",
    "  state = env.reset()\n",
    "  while True:\n",
    "    # Choose an action\n",
    "    action = np.argmax(q_table[state])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    next_state, reward, done = env.step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    q_table[state][action] = (1 - alpha) * q_table[state][action] + alpha * (reward + gamma * np.max(q_table[next_state]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "# Initialize the environment\n",
    "env = FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "q_table = np.zeros((env.n_states, env.n_actions))\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Train the agent\n",
    "q_learning(env, q_table, alpha, gamma)\n",
    "qLearning <- function(env, qTable, alpha, gamma) {\n",
    "  state <- env$reset()\n",
    "  while (TRUE) {\n",
    "    # Choose an action\n",
    "    action <- which.max(qTable[state, ])\n",
    "\n",
    "    # Take the action and observe the reward and next state\n",
    "    nextState, reward, done <- env$step(action)\n",
    "\n",
    "    # Update the Q-table\n",
    "    qTable[state, action] <- (1 - alpha) * qTable[state, action] + alpha * (reward + gamma * max(qTable[nextState, ]))\n",
    "\n",
    "    # If the episode is done, break\n",
    "    if (done) {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state <- nextState;\n",
    "  }\n",
    "}\n",
    "\n",
    "# Initialize the environment\n",
    "env <- FrozenLakeEnv()\n",
    "\n",
    "# Initialize the Q-table\n",
    "qTable <- matrix(0, nrow = env$n_states, ncol = env$n_actions)\n",
    "\n",
    "# Initialize the learning rate and discount factor\n",
    "alpha <- 0.1\n",
    "gamma <- 0.9\n",
    "\n",
    "# Train the agent\n",
    "qLearning(env, qTable, alpha, gamma)\n",
    "package main\n",
    "\n",
    "import (\n",
    "  \"fmt\"\n",
    "  \"math/rand\"\n",
    ")\n",
    "\n",
    "func main() {\n",
    "  // Initialize the environment\n",
    "  env := FrozenLakeEnv()\n",
    "\n",
    "  // Initialize the Q-table\n",
    "  qTable := make([][]float64, env.n_states)\n",
    "  for i := range qTable {\n",
    "    qTable[i] = make([]float64, env.n_actions)\n",
    "  }\n",
    "\n",
    "  // Initialize the learning rate and discount factor\n",
    "  alpha := 0.1\n",
    "  gamma := 0.9\n",
    "\n",
    "  // Train the agent\n",
    "  for i := 0; i < 10000; i++ {\n",
    "    // Choose an action\n",
    "    state := env.reset()\n",
    "    action := rand.Intn(env.n_actions)\n",
    "\n",
    "    // Take the action and observe the reward and next state\n",
    "    nextState, reward, done := env.step(action)\n",
    "\n",
    "    // Update the Q-table\n",
    "    qTable[state][action] = (1 - alpha) * qTable[state][action] + alpha * (reward + gamma * max(qTable[nextState]))\n",
    "\n",
    "    // If the episode is done, break\n",
    "    if done {\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    state = nextState;\n",
    "  }\n",
    "\n",
    "  // Print the Q-table\n",
    "  for i := 0; i < env.n_states; i++ {\n",
    "    for j := 0; j < env.n_actions; j++ {\n",
    "      fmt.Printf(\"%f \", qTable[i][j])\n",
    "    }\n",
    "    fmt.Println()\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45845a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
